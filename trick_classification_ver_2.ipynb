{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf;\n",
    "import os;\n",
    "import cv2;\n",
    "import numpy as np;\n",
    "import tqdm;\n",
    "from sklearn.preprocessing import LabelBinarizer;\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH = '/Users/nibabi/Desktop/skateboard_trick_classification/Tricks'\n",
    "VIDEOS_PATH = os.path.join(BASE_PATH, '**','*.mov')\n",
    "SEQUENCE_LENGTH = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_generator():\n",
    "    video_paths = tf.io.gfile.glob(VIDEOS_PATH)\n",
    "    np.random.shuffle(video_paths)\n",
    "    for video_path in video_paths:\n",
    "        \n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        sample_every_frame = max(1, num_frames // SEQUENCE_LENGTH)\n",
    "        current_frame = 0\n",
    "        \n",
    "        max_images = SEQUENCE_LENGTH\n",
    "        while True:\n",
    "            success, frame = cap.read()\n",
    "            if not success:\n",
    "                break\n",
    "\n",
    "            if current_frame % sample_every_frame == 0:\n",
    "                # OPENCV reads in BGR, tensorflow expects RGB so we invert the order\n",
    "                frame = frame[:, :, ::-1]\n",
    "                img = tf.image.resize(frame, (299, 299))\n",
    "                # 数据增强操作\n",
    "                img = tf.image.random_flip_left_right(img)  # 随机水平翻转\n",
    "                img = tf.image.random_flip_up_down(img)     # 随机垂直翻转\n",
    "                \n",
    "                # 随机调整亮度和对比度\n",
    "                img = tf.image.random_brightness(img, max_delta=0.3)\n",
    "                img = tf.image.random_contrast(img, lower=0.8, upper=1.2)\n",
    "                \n",
    "                img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "                max_images -= 1\n",
    "                \n",
    "                yield img, video_path\n",
    "\n",
    "            current_frame += 1\n",
    "\n",
    "            if max_images == 0:\n",
    "                break\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(frame_generator,\n",
    "             output_types=(tf.float32, tf.string),\n",
    "             output_shapes=((299, 299, 3), ()))\n",
    "\n",
    "dataset = dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "用inception_v3提取特征\n",
    "\"\"\"\n",
    "\n",
    "inception_v3 = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet')\n",
    "\n",
    "x = inception_v3.output\n",
    "\n",
    "pooling_output = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "feature_extraction_model = tf.keras.Model(inception_v3.input, pooling_output)\n",
    "\n",
    "current_path = None\n",
    "all_features = []\n",
    "\n",
    "for img, batch_paths in tqdm.tqdm(dataset):\n",
    "    batch_features = feature_extraction_model(img)\n",
    "    batch_features = tf.reshape(batch_features, (batch_features.shape[0], -1))\n",
    "    \n",
    "    for features, path in zip(batch_features.numpy(), batch_paths.numpy()):\n",
    "        if path != current_path and current_path is not None:\n",
    "            output_path = current_path.decode().replace('.mov', '.npy')\n",
    "            np.save(output_path, all_features)\n",
    "            all_features = []\n",
    "            \n",
    "        current_path = path\n",
    "        all_features.append(features)\n",
    "        \n",
    "if all_features:\n",
    "    output_path = current_path.decode().replace('.mov', '.npy')\n",
    "    np.save(output_path, all_features)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABELS = ['Ollie','Kickflip','Shuvit'] \n",
    "# encoder = LabelBinarizer()\n",
    "# encoder.fit(LABELS)\n",
    "\n",
    "# # LSTM + CNN\n",
    "# def generate_lstmfcn(MAX_SEQUENCE_LENGTH, NB_CLASS, NUM_CELLS=8):\n",
    "\n",
    "#     ip = tf.keras.Input(shape=(MAX_SEQUENCE_LENGTH,2048))\n",
    "\n",
    "#     x = tf.keras.layers.LSTM(NUM_CELLS)(ip)\n",
    "#     x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "#     y = tf.keras.layers.Permute((2, 1))(ip)\n",
    "#     y = tf.keras.layers.Conv1D(128, 8, padding='same', kernel_initializer='he_uniform')(y)\n",
    "#     y = tf.keras.layers.BatchNormalization()(y)\n",
    "#     y = tf.keras.layers.Activation('relu')(y)\n",
    "#     y =  tf.keras.layers.Dropout(0.5)(y)\n",
    "\n",
    "#     y = tf.keras.layers.Conv1D(256, 5, padding='same', kernel_initializer='he_uniform')(y)\n",
    "#     y = tf.keras.layers.BatchNormalization()(y)\n",
    "#     y = tf.keras.layers.Activation('relu')(y)\n",
    "#     y =  tf.keras.layers.Dropout(0.5)(y)\n",
    "\n",
    "#     y = tf.keras.layers.Conv1D(128, 3, padding='same', kernel_initializer='he_uniform')(y)\n",
    "#     y = tf.keras.layers.BatchNormalization()(y)\n",
    "#     y = tf.keras.layers.Activation('relu')(y)\n",
    "#     y =  tf.keras.layers.Dropout(0.5)(y)\n",
    "\n",
    "#     y = tf.keras.layers.GlobalAveragePooling1D()(y)\n",
    "\n",
    "#     x = tf.keras.layers.concatenate([x, y])\n",
    "    \n",
    "#     x = tf.keras.layers.Dense(512, activation='relu')(x)  # 添加额外的全连接层\n",
    "#     x = tf.keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "#     out = tf.keras.layers.Dense(NB_CLASS, activation='softmax')(x)\n",
    "\n",
    "#     model = tf.keras.Model(ip, out)\n",
    "\n",
    "#     model.summary()\n",
    "\n",
    "#     # add load model code here to fine-tune\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 常规LSTM\n",
    "\n",
    "# LABELS = ['Ollie','Kickflip','Shuvit'] \n",
    "LABELS = ['Ollie','Kickflip'] \n",
    "encoder = LabelBinarizer()\n",
    "encoder.fit(LABELS)\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Masking(mask_value=0.),\n",
    "    tf.keras.layers.LSTM(512, dropout=0.5, recurrent_dropout=0.5),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    # tf.keras.layers.Dense(len(LABELS), activation='softmax')\n",
    "    tf.keras.layers.Dense(len(LABELS), activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/nibabi/Desktop/skateboard_trick_classification/dev.txt') as f:\n",
    "    test_list = [row.strip() for row in list(f)]\n",
    "\n",
    "with open('/Users/nibabi/Desktop/skateboard_trick_classification/train.txt') as f:\n",
    "    train_list = [row.strip() for row in list(f)]\n",
    "    train_list = [row.split(' ')[0] for row in train_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator(file_list):\n",
    "    def generator():\n",
    "        np.random.shuffle(file_list)\n",
    "        for path in file_list:\n",
    "            full_path = os.path.join(BASE_PATH + '/', path).replace('.mov', '.npy')\n",
    "\n",
    "            label = os.path.basename(os.path.dirname(path))\n",
    "            features = np.load(full_path)\n",
    "\n",
    "            padded_sequence = np.zeros((SEQUENCE_LENGTH, 2048))\n",
    "            padded_sequence[0:len(features)] = np.array(features)\n",
    "\n",
    "            # transformed_label = encoder.transform([label])\n",
    "            # yield padded_sequence, transformed_label[0]\n",
    "            \n",
    "            transformed_label = encoder.transform([label])[0]\n",
    "            transformed_label = np.hstack([transformed_label, 1 - transformed_label])\n",
    "            # 确保产生的标签形状为 (2,)\n",
    "            yield padded_sequence, transformed_label\n",
    "            \n",
    "    return generator\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_generator(make_generator(train_list),\n",
    "                 output_types=(tf.float32, tf.int16),\n",
    "                 output_shapes=((SEQUENCE_LENGTH, 2048), (len(LABELS))))\n",
    "train_dataset = train_dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_generator(make_generator(test_list),\n",
    "                 output_types=(tf.float32, tf.int16),\n",
    "                 output_shapes=((SEQUENCE_LENGTH, 2048), (len(LABELS))))\n",
    "valid_dataset = valid_dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建模型\n",
    "# MAX_SEQUENCE_LENGTH = 100\n",
    "# NB_CLASS = 2\n",
    "# model = generate_lstmfcn(MAX_SEQUENCE_LENGTH, NB_CLASS)\n",
    "\n",
    "# 编译模型\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),\n",
    "              metrics=['accuracy', 'top_k_categorical_accuracy'])\n",
    "\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='log', update_freq=1000)\n",
    "history = model.fit(train_dataset, epochs=100, callbacks=[tensorboard_callback], validation_data=valid_dataset)\n",
    "\n",
    "# 提取训练和验证的损失和准确度\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_accuracy = history.history['accuracy']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# 绘制损失曲线\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Loss Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# 绘制准确度曲线\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accuracy, label='Training Accuracy')\n",
    "plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "plt.title('Accuracy Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_2023_11_17.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Kickflip/Kickflip107.mov', 'Kickflip/Kickflip18.mov', 'Ollie/Ollie11.mov', 'Kickflip/Kickflip56.mov', 'Kickflip/Kickflip82.mov', 'Kickflip/Kickflip48.mov', 'Ollie/Ollie37.mov', 'Ollie/Ollie62.mov', 'Ollie/Ollie80.mov', 'Ollie/Ollie54.mov', 'Kickflip/Kickflip74.mov', 'Kickflip/Kickflip43.mov', 'Kickflip/Kickflip58.mov', 'Kickflip/Kickflip14.mov', 'Ollie/Ollie99.mov', 'Ollie/Ollie105.mov', 'Ollie/Ollie26.mov', 'Ollie/Ollie23.mov', 'Ollie/Ollie10.mov', 'Kickflip/Kickflip91.mov', 'Ollie/Ollie84.mov', 'Ollie/Ollie74.mov', 'Kickflip/Kickflip103.mov']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-17 17:13:56.380723: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 119ms/step\n",
      "[[0.03905711 0.949884  ]\n",
      " [0.70882136 0.27686268]\n",
      " [0.42863438 0.5046203 ]\n",
      " [0.2883597  0.6155926 ]\n",
      " [0.03856493 0.9445794 ]\n",
      " [0.2274671  0.73544645]\n",
      " [0.812379   0.17566723]\n",
      " [0.55639756 0.48944595]\n",
      " [0.87919664 0.15617995]\n",
      " [0.9166672  0.10797974]\n",
      " [0.05663994 0.94277316]\n",
      " [0.49790537 0.43498817]\n",
      " [0.43083957 0.46019778]\n",
      " [0.4441958  0.51588845]\n",
      " [0.62815565 0.20274135]\n",
      " [0.52104396 0.3523688 ]\n",
      " [0.40169728 0.40218893]\n",
      " [0.9255199  0.08680146]\n",
      " [0.8440991  0.14067979]\n",
      " [0.04662992 0.94844216]\n",
      " [0.2708345  0.5504886 ]\n",
      " [0.87203085 0.11537561]\n",
      " [0.06429199 0.92152065]]\n",
      "[1 0 1 1 1 1 0 0 0 0 1 0 1 1 0 0 1 0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "with open('/Users/nibabi/Desktop/skateboard_trick_classification/test.txt') as f:\n",
    "    unknown_dataset = [row.strip() for row in list(f)]\n",
    "print(unknown_dataset)\n",
    "\n",
    "def make_generator_test(file_list):\n",
    "    def generator_test():\n",
    "        for path in file_list:\n",
    "            full_path = os.path.join(BASE_PATH + '/', path).replace('.mov', '.npy')\n",
    "            features = np.load(full_path)\n",
    "\n",
    "            padded_sequence = np.zeros((SEQUENCE_LENGTH, 2048))\n",
    "            padded_sequence[0:len(features)] = np.array(features)\n",
    "\n",
    "\n",
    "            yield padded_sequence  # 不生成标签\n",
    "\n",
    "    return generator_test\n",
    "\n",
    "unknown_dataset = tf.data.Dataset.from_generator(\n",
    "    make_generator_test(unknown_dataset),\n",
    "    output_types=tf.float32,  # 只有特征，不需要定义标签的类型\n",
    "    output_shapes=(SEQUENCE_LENGTH, 2048)  # 只有特征的形状\n",
    ")\n",
    "\n",
    "unknown_dataset = unknown_dataset.batch(16).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "predict = model.predict(unknown_dataset)\n",
    "\n",
    "\n",
    "print(predict)\n",
    "\n",
    "predicted_labels = np.argmax(predict, axis=1)\n",
    "print(predicted_labels)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ollie_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
